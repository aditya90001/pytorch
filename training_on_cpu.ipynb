{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e0140bf5",
      "metadata": {
        "id": "e0140bf5"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a4c35712",
      "metadata": {
        "id": "a4c35712",
        "outputId": "b56cff65-e48a-403c-9362-3829e2dfbb60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "42db0ae3",
      "metadata": {
        "id": "42db0ae3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VHawYiNWVHyu"
      },
      "id": "VHawYiNWVHyu",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=pd.read_csv(\"/content/fashion-mnist_train.csv\")"
      ],
      "metadata": {
        "id": "8mQ5D0bbVKlR"
      },
      "id": "8mQ5D0bbVKlR",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.shape"
      ],
      "metadata": {
        "id": "eKn3fA2xfmZa",
        "outputId": "dcdfa2eb-6d5a-4b99-b0d4-95fe79b0abaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eKn3fA2xfmZa",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33588, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features=train_dataset.drop(columns=[\"label\"]).values\n",
        "train_labels=train_dataset[\"label\"].values"
      ],
      "metadata": {
        "id": "plr5M9r2VSIG"
      },
      "id": "plr5M9r2VSIG",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset=pd.read_csv(\"/content/fashion-mnist_test.csv\")"
      ],
      "metadata": {
        "id": "J-Tz0PuxVpba"
      },
      "id": "J-Tz0PuxVpba",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features=test_dataset.drop(columns=[\"label\"]).values\n",
        "test_labels=test_dataset[\"label\"].values"
      ],
      "metadata": {
        "id": "3c4nC_fsVzgU"
      },
      "id": "3c4nC_fsVzgU",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.shape"
      ],
      "metadata": {
        "id": "7wLogzxidTip",
        "outputId": "02d67a14-d0d9-42a7-e7df-e991f893d83b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7wLogzxidTip",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "id": "itEE2sswa7TI"
      },
      "id": "itEE2sswa7TI",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customdataset(Dataset):\n",
        "  def __init__(self,features,labels):\n",
        "    self.features=torch.tensor(features,dtype=torch.float32)\n",
        "    self.labels=torch.tensor(labels,dtype=torch.long)\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "  def __getitem__(self,index):\n",
        "    return self.features[index],self.labels[index]\n"
      ],
      "metadata": {
        "id": "tdYpW2rRbhEF"
      },
      "id": "tdYpW2rRbhEF",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datasetss=customdataset(train_features,train_labels)\n",
        "test_datasetss=customdataset(test_features,test_labels)"
      ],
      "metadata": {
        "id": "fcx8DH7ccNts"
      },
      "id": "fcx8DH7ccNts",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_datasetss)"
      ],
      "metadata": {
        "id": "JKLIHXmjep6f",
        "outputId": "0374704f-f824-4abd-d5cd-70db169a16ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JKLIHXmjep6f",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33588"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datasetss[0]"
      ],
      "metadata": {
        "id": "Pp8T3e56e8KW",
        "outputId": "29d165fb-28ae-4f91-a9ec-115749c7c45d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Pp8T3e56e8KW",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   4.,   0.,   0.,   0.,   0.,   0.,  62.,  61.,\n",
              "          21.,  29.,  23.,  51., 136.,  61.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  88.,\n",
              "         201., 228., 225., 255., 115.,  62., 137., 255., 235., 222., 255., 135.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,  47., 252., 234., 238., 224., 215., 215., 229., 108., 180., 207.,\n",
              "         214., 224., 231., 249., 254.,  45.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   1.,   0.,   0., 214., 222., 210., 213., 224., 225., 217.,\n",
              "         220., 254., 233., 219., 221., 217., 223., 221., 240., 254.,   0.,   0.,\n",
              "           1.,   0.,   0.,   0.,   1.,   0.,   0.,   0., 128., 237., 207., 224.,\n",
              "         224., 207., 216., 214., 210., 208., 211., 221., 208., 219., 213., 226.,\n",
              "         211., 237., 150.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,\n",
              "         237., 222., 215., 207., 210., 212., 213., 206., 214., 213., 214., 213.,\n",
              "         210., 215., 214., 206., 199., 218., 255.,  13.,   0.,   2.,   0.,   0.,\n",
              "           0.,   4.,   0.,  85., 228., 210., 218., 200., 211., 208., 203., 215.,\n",
              "         210., 209., 209., 210., 213., 211., 210., 217., 206., 213., 231., 175.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0., 217., 224., 215., 206., 205.,\n",
              "         204., 217., 230., 222., 215., 224., 233., 228., 232., 228., 224., 207.,\n",
              "         212., 215., 213., 229.,  31.,   0.,   4.,   0.,   1.,   0.,  21., 225.,\n",
              "         212., 212., 203., 211., 225., 193., 139., 136., 195., 147., 156., 139.,\n",
              "         128., 162., 197., 223., 207., 220., 213., 232., 177.,   0.,   0.,   0.,\n",
              "           0.,   0., 123., 226., 207., 211., 209., 205., 228., 158.,  90., 103.,\n",
              "         186., 138., 100., 121., 147., 158., 183., 226., 208., 214., 209., 216.,\n",
              "         255.,  13.,   0.,   1.,   0.,   0., 226., 219., 202., 208., 206., 205.,\n",
              "         216., 184., 156., 150., 193., 170., 164., 168., 188., 186., 200., 219.,\n",
              "         216., 213., 213., 211., 233., 148.,   0.,   0.,   0.,  45., 227., 204.,\n",
              "         214., 211., 218., 222., 221., 230., 229., 221., 213., 224., 233., 226.,\n",
              "         220., 219., 221., 224., 223., 217., 210., 218., 213., 254.,   0.,   0.,\n",
              "           0., 157., 226., 203., 207., 211., 209., 215., 205., 198., 207., 208.,\n",
              "         201., 201., 197., 203., 205., 210., 207., 213., 214., 214., 214., 213.,\n",
              "         208., 234., 107.,   0.,   0., 235., 213., 204., 211., 210., 209., 213.,\n",
              "         202., 197., 204., 215., 217., 213., 212., 210., 206., 212., 203., 211.,\n",
              "         218., 215., 214., 208., 209., 222., 230.,   0.,  52., 255., 207., 200.,\n",
              "         208., 213., 210., 210., 208., 207., 202., 201., 209., 216., 216., 216.,\n",
              "         216., 214., 212., 205., 215., 201., 228., 208., 214., 212., 218.,  25.,\n",
              "         118., 217., 201., 206., 208., 213., 208., 205., 206., 210., 211., 202.,\n",
              "         199., 207., 208., 209., 210., 207., 210., 210., 245., 139., 119., 255.,\n",
              "         202., 203., 236., 114., 171., 238., 212., 203., 220., 216., 217., 209.,\n",
              "         207., 205., 210., 211., 206., 204., 206., 209., 211., 215., 210., 206.,\n",
              "         221., 242.,   0., 224., 234., 230., 181.,  26.,  39., 145., 201., 255.,\n",
              "         157., 115., 250., 200., 207., 206., 207., 213., 216., 206., 205., 206.,\n",
              "         207., 206., 215., 207., 221., 238.,   0.,   0., 188.,  85.,   0.,   0.,\n",
              "           0.,   0.,   0.,  31.,   0., 129., 253., 190., 207., 208., 208., 208.,\n",
              "         209., 211., 211., 209., 209., 209., 212., 201., 226., 165.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,  89., 254., 199.,\n",
              "         199., 192., 196., 198., 199., 201., 202., 203., 204., 203., 203., 200.,\n",
              "         222., 155.,   0.,   3.,   3.,   3.,   2.,   0.,   0.,   0.,   1.,   5.,\n",
              "           0.,   0., 255., 218., 226., 232., 228., 224., 222., 220., 219., 219.,\n",
              "         217., 221., 220., 212., 236.,  95.,   0.,   2.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0., 155., 194., 168., 170., 171., 173.,\n",
              "         173., 179., 177., 175., 172., 171., 167., 161., 180.,   0.,   0.,   1.,\n",
              "           0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.]),\n",
              " tensor(2))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=DataLoader(train_datasetss,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "h_RJgKgIeJ_0"
      },
      "id": "h_RJgKgIeJ_0",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataloader)"
      ],
      "metadata": {
        "id": "pw8LmODKejXX",
        "outputId": "20d47e59-876f-499b-a3f0-67a1aa8ca836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pw8LmODKejXX",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1050"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "VC4pdXrFWN8j"
      },
      "id": "VC4pdXrFWN8j",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create model\n",
        "class models(nn.Module):\n",
        "  def __init__(self,num_features):\n",
        "    super().__init__()\n",
        "    self.network=nn.Sequential(\n",
        "        nn.Linear(num_features,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,10)\n",
        "    )\n",
        "  def forward(self,features):\n",
        "    out=self.network(features)\n",
        "    return out"
      ],
      "metadata": {
        "id": "kBTxeahYWEHq"
      },
      "id": "kBTxeahYWEHq",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "learning_rate=0.01"
      ],
      "metadata": {
        "id": "SDtevEzQZJoD"
      },
      "id": "SDtevEzQZJoD",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=models(train_features.shape[1])"
      ],
      "metadata": {
        "id": "gkst5QuBYuvP"
      },
      "id": "gkst5QuBYuvP",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move to gpu first step is\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "LRD70IheZ4D1",
        "outputId": "da93b9d5-3bea-4d2a-9e38-bdd3f0c6dc78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LRD70IheZ4D1",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=model.to(device)"
      ],
      "metadata": {
        "id": "FrMqLpXKaN17"
      },
      "id": "FrMqLpXKaN17",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## intialize loss function\n",
        "criterion=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "zW1YAYkIbPo0"
      },
      "id": "zW1YAYkIbPo0",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## OPtmizers\n",
        "import torch.optim as optim\n",
        "\n",
        "optmizers=optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "KExE7Mrwbwc_"
      },
      "id": "KExE7Mrwbwc_",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_epoch_loss=0\n",
        "  for batch_features,batch_labels in dataloader:\n",
        "    batch_features=batch_features.to(device)\n",
        "    batch_labels=batch_labels.to(device)\n",
        "    output=model(batch_features)\n",
        "    loss=criterion(output,batch_labels)\n",
        "    optmizers.zero_grad()\n",
        "    loss.backward()\n",
        "    optmizers.step()\n",
        "    total_epoch_loss+=loss.item()\n",
        "  avg_epoch_loss=total_epoch_loss\\len(train_dataloader)"
      ],
      "metadata": {
        "id": "f96_3ZEwdPFN"
      },
      "id": "f96_3ZEwdPFN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}